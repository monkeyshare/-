https://blog.csdn.net/Eastmount/article/details/71308373
import numpy as np
import math
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import tensorflow as tf
#plt 设置正常显示中文与负号
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False
def computeYByx(x):
    noise=np.random.normal(-100,100,x.shape)
    return 400*np.sin(x)+2*x*x+noise
# x_train=np.linspace(-20,20,401).reshape([1,-1])
# noise=np.random.normal(-0.2,0.2,x_train.shape)
# y_train=computeYByx(x_train)
x=range(1,402)
y=[20000*pow(i,-0.5)+5 for i in x]
x_train=np.array([x])
y_train=np.array([y])
plt.clf()
plt.plot(x_train[0],y_train[0],'ro',label=u'训练数据')
plt.legend()
x=tf.placeholder(tf.float32,[1,401])
def weight_variable(shape):
    initial=tf.truncated_normal(shape,stddev=0.1) #从正态分布中得到随机
    return tf.Variable(initial)
def bias_variable(shape):
    initial=tf.constant(0.1,shape=shape)
    return tf.Variable(initial)
hiddenDim=400
W=weight_variable([hiddenDim,1]) #W 被初始化为hiddenDim的符合正态分布的随机
b=bias_variable([hiddenDim,1])
W2=weight_variable([1,hiddenDim])
b2=bias_variable([1])
W3=weight_variable([401,401])
b3=bias_variable([1,401])

hidden=tf.nn.sigmoid(tf.matmul(W,x)+b)
y=tf.matmul(W2,hidden)+b2

loss=tf.reduce_mean(tf.square(y-y_train))
step=tf.Variable(0,trainable=False)
rate=tf.train.exponential_decay(0.15,step,1,0.9999)
optimizer=tf.train.AdamOptimizer(rate)
train=optimizer.minimize(loss,global_step=step)
init=tf.global_variables_initializer()

sess=tf.Session()
sess.run(init)
for time in range(0,10001):
    train.run({x:x_train},sess)
    if time%1000==0:
#         print('训练次数：',time,'训练平均损失值：',loss.eval({x:x_train},sess)[0])
        plt.clf()
        plt.plot(x_train[0],y_train[0],'ro',label=u'训练数据')
        plt.plot(x_train[0],y.eval({x:x_train},sess)[0],label=u'拟合曲线')
        plt.legend()
    
